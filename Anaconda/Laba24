import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier, BaggingClassifier, AdaBoostClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import GridSearchCV
import matplotlib.pyplot as plt
import seaborn as sns

print("\n=== Завдання 1: Завантаження даних ===")
data = pd.read_csv('HeartDiseaseTrain-Test.csv')
print("Дані успішно завантажено. Розмір датасету:", data.shape)

print("\n=== Завдання 2: Підготовка даних ===")
print("Пропущені значення:\n", data.isnull().sum())

categorical_features = ['sex', 'chest_pain_type', 'fasting_blood_sugar', 'rest_ecg', 
                       'exercise_induced_angina', 'slope', 'vessels_colored_by_flourosopy', 'thalassemia']
numeric_features = ['age', 'resting_blood_pressure', 'cholestoral', 'Max_heart_rate', 'oldpeak']

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ])
X = data.drop('target', axis=1)
y = data['target']

# Розділення на навчальний та тестовий набори
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
print("Дані підготовлено. Розміри:")
print("X_train:", X_train.shape, "X_test:", X_test.shape)

print("\n=== Завдання 3: Створення гомогенних ансамблів ===")
print("\nСтворення одиночних моделей...")
log_reg = Pipeline(steps=[('preprocessor', preprocessor),
                          ('classifier', LogisticRegression(random_state=42))])

rf = Pipeline(steps=[('preprocessor', preprocessor),
                     ('classifier', RandomForestClassifier(random_state=42))])
log_reg.fit(X_train, y_train)
rf.fit(X_train, y_train)

print("\nОцінка одиночних моделей:")
print("Logistic Regression Accuracy:", accuracy_score(y_test, log_reg.predict(X_test)))
print("Random Forest Accuracy:", accuracy_score(y_test, rf.predict(X_test)))

print("\nСтворення паралельного ансамблю (Voting)...")
parallel_ensemble = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', VotingClassifier(
        estimators=[
            ('lr', LogisticRegression(random_state=42)),
            ('rf', RandomForestClassifier(random_state=42))],
        voting='soft'))
])

parallel_ensemble.fit(X_train, y_train)
parallel_pred = parallel_ensemble.predict(X_test)
print("Паралельний ансамбль (Voting) Accuracy:", accuracy_score(y_test, parallel_pred))

print("\nСтворення послідовного ансамблю (Stacking)...")
stacking_ensemble = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', StackingClassifier(
        estimators=[
            ('lr', LogisticRegression(random_state=42)),
            ('rf', RandomForestClassifier(random_state=42))],
        final_estimator=LogisticRegression()))
])

stacking_ensemble.fit(X_train, y_train)
stacking_pred = stacking_ensemble.predict(X_test)
print("Послідовний ансамбль (Stacking) Accuracy:", accuracy_score(y_test, stacking_pred))
=
print("\n=== Завдання 4: Інтеграція прогнозів для паралельного ансамблю ===")

base_models = [
    ('lr', LogisticRegression(random_state=42)),
    ('rf', RandomForestClassifier(random_state=42)),
    ('svm', SVC(probability=True, random_state=42))
]

def get_predictions(models, X_train, X_test, y_train):
    train_preds = []
    test_preds = []
    for name, model in models:
        pipeline = Pipeline([
            ('preprocessor', preprocessor),
            ('classifier', model)
        ])
        pipeline.fit(X_train, y_train)
        
        if hasattr(model, 'predict_proba'):
            train_pred = pipeline.predict_proba(X_train)[:, 1] 
            test_pred = pipeline.predict_proba(X_test)[:, 1]
        else:
            train_pred = pipeline.predict(X_train)
            test_pred = pipeline.predict(X_test)
        
        train_preds.append(train_pred)
        test_preds.append(test_pred)
    
    return np.array(train_preds).T, np.array(test_preds).T

train_preds, test_preds = get_predictions(base_models, X_train, X_test, y_train)

print("\nПростий метод: Max Voting (Більшість голосів)")

binary_train_preds = (train_preds > 0.5).astype(int)
binary_test_preds = (test_preds > 0.5).astype(int)

max_vote_train = np.apply_along_axis(lambda x: np.argmax(np.bincount(x)), axis=1, arr=binary_train_preds)
max_vote_test = np.apply_along_axis(lambda x: np.argmax(np.bincount(x)), axis=1, arr=binary_test_preds)

# Оцінка точності
max_vote_accuracy = accuracy_score(y_test, max_vote_test)
print("Max Voting Accuracy:", max_vote_accuracy)

print("\nСкладний метод: Blending (з використанням мета-моделі)")

# Розділяємо навчальний набір на два піднабори
X_train_blend, X_val, y_train_blend, y_val = train_test_split(
    X_train, y_train, test_size=0.3, random_state=42)

# Отримуємо прогнози для валідаційного набору
_, val_preds = get_predictions(base_models, X_train_blend, X_val, y_train_blend)

# Тренуємо мета-модель на прогнозах базових моделей
meta_model = LogisticRegression()
meta_model.fit(val_preds, y_val)

# Отримуємо прогнози для тестового набору
test_meta_features = test_preds

# Робимо прогноз за допомогою мета-моделі
blend_pred = meta_model.predict(test_meta_features)

# Оцінка точності
blend_accuracy = accuracy_score(y_test, blend_pred)
print("Blending Accuracy:", blend_accuracy)

methods = ['Max Voting', 'Blending']
accuracies = [max_vote_accuracy, blend_accuracy]

plt.figure(figsize=(8, 5))
sns.barplot(x=methods, y=accuracies)
plt.title('Порівняння методів інтеграції прогнозів')
plt.ylabel('Accuracy')
plt.ylim(0.8, 1.0)
for i, acc in enumerate(accuracies):
    plt.text(i, acc + 0.01, f"{acc:.4f}", ha='center')
plt.show()

print("\nДодатковий аналіз для методу Blending:")
print("\nЗвіт класифікації:")
print(classification_report(y_test, blend_pred))

print("\nМатриця плутанини:")
conf_matrix = confusion_matrix(y_test, blend_pred)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title('Матриця плутанини для Blending')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

print("\nВаги мета-моделі для кожного базового класифікатора:")
for model_name, weight in zip([m[0] for m in base_models], meta_model.coef_[0]):
    print(f"{model_name}: {weight:.4f}")

print("\n=== Завдання 5: Підбір оптимальних параметрів ===")
# Для паралельного ансамблю
print("\nПідбір параметрів для паралельного ансамблю...")
param_grid = {
    'classifier__voting': ['hard', 'soft'],
    'classifier__weights': [[1, 1], [1, 2], [2, 1]]
}

grid_search = GridSearchCV(parallel_ensemble, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)
print("Найкращі параметри для паралельного ансамблю:", grid_search.best_params_)
print("Найкраща точність:", grid_search.best_score_)

print("\nПідбір параметрів для послідовного ансамблю...")
param_grid = {
    'classifier__final_estimator': [LogisticRegression(), DecisionTreeClassifier()]
}

grid_search = GridSearchCV(stacking_ensemble, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)
print("Найкращі параметри для послідовного ансамблю:", grid_search.best_params_)
print("Найкраща точність:", grid_search.best_score_)

print("\n=== Завдання 6: Аналіз важливості ознак ===")
# Отримаємо важливість ознак з Random Forest
rf_model = rf.named_steps['classifier']
rf_feature_importances = rf_model.feature_importances_

# Отримаємо назви ознак після OneHotEncoding
cat_encoder = preprocessor.named_transformers_['cat']
cat_feature_names = cat_encoder.get_feature_names_out(categorical_features)
all_feature_names = np.concatenate([numeric_features, cat_feature_names])

feature_importance_df = pd.DataFrame({
    'Feature': all_feature_names,
    'Importance': rf_feature_importances
}).sort_values('Importance', ascending=False)

print("\nТоп-10 найважливіших ознак:")
print(feature_importance_df.head(10))

# Візуалізація важливості ознак
plt.figure(figsize=(12, 8))
sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(20))
plt.title('Топ-20 найважливіших ознак (Random Forest)')
plt.tight_layout()
plt.show()

print("\n=== Завдання 7: N-рівневий гомогенний ансамбль ===")

print("\nСтворення першого рівня (Bagging)...")
bagging_model = Pipeline([
    ('preprocessor', preprocessor),
    ('bagging', BaggingClassifier(
        estimator=RandomForestClassifier(),
        n_estimators=10,
        random_state=42))
])

bagging_model.fit(X_train, y_train)
bagging_pred = bagging_model.predict(X_test)
print("Bagging Accuracy:", accuracy_score(y_test, bagging_pred))

print("\nСтворення другого рівня (Boosting)...")
boosting_model = Pipeline([
    ('preprocessor', preprocessor),
    ('boosting', AdaBoostClassifier(
        n_estimators=50,
        random_state=42))
])

boosting_model.fit(X_train, y_train)
boosting_pred = boosting_model.predict(X_test)
print("Boosting Accuracy:", accuracy_score(y_test, boosting_pred))

print("\nСтворення третього рівня (Stacking)...")
stacking_model = Pipeline([
    ('preprocessor', preprocessor),
    ('stacking', StackingClassifier(
        estimators=[
            ('lr', LogisticRegression(random_state=42)),
            ('rf', RandomForestClassifier(random_state=42)),
            ('svm', SVC(probability=True, random_state=42))],
        final_estimator=LogisticRegression()))
])

stacking_model.fit(X_train, y_train)
stacking_pred = stacking_model.predict(X_test)
print("Stacking Accuracy:", accuracy_score(y_test, stacking_pred))

print("\nСтворення комбінованого багаторівневого ансамблю...")
X_train_meta = pd.DataFrame({
    'bagging': bagging_model.predict(X_train),
    'boosting': boosting_model.predict(X_train),
    'stacking': stacking_model.predict(X_train)
})

X_test_meta = pd.DataFrame({
    'bagging': bagging_model.predict(X_test),
    'boosting': boosting_model.predict(X_test),
    'stacking': stacking_model.predict(X_test)
})

meta_model = LogisticRegression()
meta_model.fit(X_train_meta, y_train)
meta_pred = meta_model.predict(X_test_meta)
print("Багаторівневий ансамбль Accuracy:", accuracy_score(y_test, meta_pred))

print("\n=== Порівняння всіх моделей ===")
models = {
    'Logistic Regression': log_reg,
    'Random Forest': rf,
    'Parallel Ensemble': parallel_ensemble,
    'Stacking Ensemble': stacking_ensemble,
    'Bagging': bagging_model,
    'Boosting': boosting_model,
    'Stacking': stacking_model,
    'Multi-level Ensemble': meta_model 
}

results = {}
for name, model in models.items():
    if name == 'Multi-level Ensemble':
        results[name] = accuracy_score(y_test, model.predict(X_test_meta))
    else:
        results[name] = accuracy_score(y_test, model.predict(X_test))

results_df = pd.DataFrame.from_dict(results, orient='index', columns=['Accuracy'])
print("\nПорівняння моделей:")
print(results_df.sort_values('Accuracy', ascending=False))

plt.figure(figsize=(12, 6))
sns.barplot(x=results_df.index, y=results_df['Accuracy'])
plt.xticks(rotation=45)
plt.title('Порівняння точності всіх моделей')
plt.ylabel('Accuracy')
plt.ylim(0.8, 1.0)
plt.tight_layout()
plt.show()
